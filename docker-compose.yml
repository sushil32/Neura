version: "3.9"

services:
  postgres:
    image: postgres:15-alpine
    container_name: neura-postgres
    environment:
      POSTGRES_DB: neura
      POSTGRES_USER: neura
      POSTGRES_PASSWORD: neura_dev_password
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U neura -d neura" ]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: neura-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio:latest
    container_name: neura-minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: neura_minio
      MINIO_ROOT_PASSWORD: neura_minio_password
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: neura-backend
    ports:
      - "8000:8000"
    env_file:
      - .env.local
    environment:
      - TTS_SERVICE_URL=http://host.docker.internal:8001
    volumes:
      - ./backend:/app
      - ./services:/app/services
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: neura-frontend
    ports:
      - "3000:3000"
    env_file:
      - .env.local
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - backend
    command: npm run dev

  celery-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: neura-celery-worker
    env_file:
      - .env.local
    volumes:
      - ./backend:/app
      - ./services:/app/services
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: celery -A app.workers.celery_app worker --loglevel=info --concurrency=2 -Q celery,gpu,default

  celery-beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: neura-celery-beat
    env_file:
      - .env.local
    volumes:
      - ./backend:/app
    depends_on:
      - celery-worker
    command: celery -A app.workers.celery_app beat --loglevel=info

  flower:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: neura-flower
    env_file:
      - .env.local
    ports:
      - "5555:5555"
    depends_on:
      - redis
      - celery-worker
    command: celery -A app.workers.celery_app flower --port=5555

  # TTS service (Coqui XTTS) - works with or without GPU
  tts-service:
    build:
      context: ./services/tts
      dockerfile: Dockerfile
    container_name: neura-tts
    env_file:
      - .env.local

    volumes:
      - ./services/tts:/app
      - tts_models:/app/models
      - voice_samples:/app/voices
    ports:
      - "8001:8001"
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    # Disable healthcheck temporarily - model loading takes 5+ minutes on CPU
    healthcheck:
      disable: true
    # GPU support (optional - uncomment if GPU available)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

    # Live Service (WebRTC/aiortc)
  live-service:
    build:
      context: ./services/live
      dockerfile: Dockerfile
    container_name: neura-live
    network_mode: host
    environment:
      - PORT=8003
      - LOG_LEVEL=info
      - DEEPGRAM_API_KEY=${DEEPGRAM_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - TTS_SERVICE_URL=http://localhost:8001
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8003/health" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # Avatar service (Wav2Lip) - works with or without GPU
  avatar-service:
    build:
      context: ./services/avatar
      dockerfile: Dockerfile
    container_name: neura-avatar
    env_file:
      - .env.local
    volumes:
      - ./services/avatar:/app
      - avatar_models:/app/models
      - avatar_images:/app/avatars
    ports:
      - "8002:8002"
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8002/health').read()" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # GPU support (optional - uncomment if GPU available)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

volumes:
  postgres_data:
  redis_data:
  minio_data:
  tts_models:
  voice_samples:
  avatar_models:
  avatar_images:


